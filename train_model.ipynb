{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "adipose_train3",
   "display_name": "adipose_train3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/jaentrouble/adipose_train3\n"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/jaentrouble/adipose_train3')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as io\n",
    "import json\n",
    "\n",
    "img_names = os.listdir('data/done')\n",
    "img = []\n",
    "img_name_dict = {}\n",
    "for idx, name in enumerate(img_names):\n",
    "    img.append(io.imread('data/done/'+name))\n",
    "    img_name_dict[name] = idx\n",
    "\n",
    "json_names = os.listdir('data/save')\n",
    "data = []\n",
    "for name in json_names:\n",
    "    with open('data/save/'+name,'r') as j:\n",
    "        data.extend(json.load(j))\n",
    "for datum in data :\n",
    "    datum['image'] = img_name_dict[datum['image']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "remote: Enumerating objects: 7, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (1/1), done.\u001b[K\nremote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\nUnpacking objects: 100% (4/4), 620 bytes | 206.00 KiB/s, done.\nFrom https://github.com/jaentrouble/Adipose_tf_train3\n   1398cdf..c9052ef  master     -> origin/master\nUpdating 1398cdf..c9052ef\nFast-forward\n encoder_models.py | 7 \u001b[32m++\u001b[m\u001b[31m-----\u001b[m\n train_model.ipynb | 6 \u001b[32m+++\u001b[m\u001b[31m---\u001b[m\n 2 files changed, 5 insertions(+), 8 deletions(-)\n"
    }
   ],
   "source": [
    "!git pull\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_trainer import run_training\n",
    "from encoder_models import *\n",
    "from box_models import *\n",
    "from model_lr import *\n",
    "from multiprocessing import Process\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_f = hr_5_3_0_gap\n",
    "img_size = (400,320)\n",
    "box_f = partial(dense_128_4_norm, image_size=img_size)\n",
    "lr_f = lr_mul_inv\n",
    "name = 'hr_5_3_0_d128_test'\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "steps_per_epoch = len(data)//batch_size\n",
    "mixed_float = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    encoder_f = encoder_f,\n",
    "    box_f = box_f,\n",
    "    lr_f = lr_f,\n",
    "    name = name,\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    mixed_float=mixed_float,\n",
    "    batch_size=batch_size,\n",
    "    img=img,\n",
    "    data=data,\n",
    "    img_size=img_size,\n",
    "    notebook= True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\nYour GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 2070 SUPER, compute capability 7.5\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'image_ratio' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-04fb5cdcabb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/adipose_train3/model_trainer.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(encoder_f, box_f, lr_f, name, epochs, batch_size, steps_per_epoch, img, data, img_size, mixed_float, notebook)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;34m'pos'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     }\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mmymodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoxModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredLogarithmicError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     mymodel.compile(\n",
      "\u001b[0;32m~/adipose_train3/model_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, encoder_function, box_function)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mbox_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         self.box_model = keras.Model(inputs=[encoded_input, pos_input],\n\u001b[1;32m     62\u001b[0m                                      outputs=box_output)\n",
      "\u001b[0;32m~/adipose_train3/box_models.py\u001b[0m in \u001b[0;36mdense_128_4_norm\u001b[0;34m(encode_input, pos_input, image_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m     ])\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_ratio' is not defined"
     ]
    }
   ],
   "source": [
    "run_training(**kwargs)"
   ]
  }
 ]
}